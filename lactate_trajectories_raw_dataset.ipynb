{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589757e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from scipy.stats import pearsonr\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import create_registry_case_identification_column, create_ehr_case_identification_column, patient_selection\n",
    "from utils import load_data_from_main_dir\n",
    "from lab_preprocessing import preprocess_labs\n",
    "from outcome_preprocessing import preprocess_outcomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdca6c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eds_path = '/Users/jk1/stroke_datasets/stroke_unit_dataset/per_value/Extraction_20221117/eds_j1.csv'\n",
    "ehr_data_path = '/Users/jk1/stroke_datasets/stroke_unit_dataset/per_value/Extraction_20221117/'\n",
    "registry_path = '/Users/jk1/Library/CloudStorage/OneDrive-unige.ch/stroke_research/geneva_stroke_unit_dataset/data/stroke_registry/post_hoc_modified/stroke_registry_post_hoc_modified.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2905607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eds_df = pd.read_csv(eds_path, delimiter=';', encoding='utf-8',\n",
    "                         dtype=str)\n",
    "registry_df = pd.read_excel(registry_path, dtype=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b8dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_df['case_admission_id'] = create_registry_case_identification_column(registry_df)\n",
    "eds_df['case_admission_id'] = create_ehr_case_identification_column(eds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa410071",
   "metadata": {},
   "outputs": [],
   "source": [
    "eds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08e52b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inclusion_registry_df, excluded_patients_df = patient_selection(\n",
    "    registry_path=registry_path,\n",
    "    eds_path=eds_path,\n",
    "    exclude_patients_under_18=True,\n",
    "    exclude_non_ischemic_stroke=True,\n",
    "    exclude_non_acute_stroke=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93d5161",
   "metadata": {},
   "outputs": [],
   "source": [
    "eds_df['case_admission_id'] = eds_df[eds_df['case_admission_id'].isin(inclusion_registry_df['case_admission_id'])]['case_admission_id']\n",
    "print(f'Number of patients in EDS after selection: {eds_df.patient_id.nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2083ff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_df.case_admission_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189763b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_file_start = 'labo'\n",
    "lab_df = load_data_from_main_dir(ehr_data_path, lab_file_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bed43d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_df['case_admission_id'] = create_ehr_case_identification_column(lab_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9bfa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_lactate_df = preprocess_labs(lab_df, [\"lactate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91fa07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_lactate_df = preprocessed_lactate_df[preprocessed_lactate_df['case_admission_id'].isin(inclusion_registry_df['case_admission_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc90d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_lactate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dce2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_lactate_df.unit_of_measure.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb5f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_lactate_df.value.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e904c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inclusion_registry_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a36151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inclusion_registry_df['stroke_dt'].isna().sum(), inclusion_registry_df['arrival_dt'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aa8ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inclusion_registry_df['T0'] = inclusion_registry_df['stroke_dt'].fillna(inclusion_registry_df['arrival_dt'])\n",
    "preprocessed_lactate_df = preprocessed_lactate_df.merge(\n",
    "    inclusion_registry_df[['case_admission_id', 'T0']],\n",
    "    on='case_admission_id',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e63c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_format = '%d.%m.%Y %H:%M'\n",
    "preprocessed_lactate_df['relative_sample_date'] = (pd.to_datetime(preprocessed_lactate_df['sample_date'], format=dt_format) - pd.to_datetime(preprocessed_lactate_df['T0'], format=dt_format)).dt.total_seconds() / 3600 # convert to hours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c586a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_lactate_df['sample_date'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732c7990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "preprocessed_lactate_df['relative_sample_date_hcat'] = preprocessed_lactate_df['relative_sample_date'].apply(np.floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3ccd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_lactate_df[['T0', 'sample_date', 'relative_sample_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2108f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sns.set(style=\"whitegrid\")\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# ax = sns.lineplot(x='relative_sample_date_hcat', y='value', data=preprocessed_lactate_df)\n",
    "\n",
    "# ax.set_xlim(-24, 7*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810a61a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_lactate_df.case_admission_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36116211",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patients_with_lactate_in_first_24h = preprocessed_lactate_df[(preprocessed_lactate_df.relative_sample_date > -12) & (preprocessed_lactate_df.relative_sample_date < 24)].case_admission_id.nunique()\n",
    "n_patients_with_lactate_in_24_to_72h = preprocessed_lactate_df[(preprocessed_lactate_df.relative_sample_date > 24) & (preprocessed_lactate_df.relative_sample_date < 3*24)].case_admission_id.nunique()\n",
    "\n",
    "print(f'Number of patients with lactate in first 24h: {n_patients_with_lactate_in_first_24h}')\n",
    "print(f'Number of patients with lactate in 24 to 72h: {n_patients_with_lactate_in_24_to_72h}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1be921",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_df = preprocess_outcomes(registry_path)\n",
    "outcome_df = outcome_df[outcome_df.case_admission_id.isin(inclusion_registry_df.case_admission_id.unique())]\n",
    "outcome_df.drop_duplicates(subset='case_admission_id', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed82ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_lactate_df = preprocessed_lactate_df.merge(\n",
    "    outcome_df[['case_admission_id', '3M mRS']],\n",
    "    on='case_admission_id',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb4a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_lactate_df = preprocessed_lactate_df[(preprocessed_lactate_df.relative_sample_date > -12) & (preprocessed_lactate_df.relative_sample_date < 24)]\n",
    "lactate_d2_df = preprocessed_lactate_df[(preprocessed_lactate_df.relative_sample_date > 24) & (preprocessed_lactate_df.relative_sample_date < 2*72)]\n",
    "lactate_d3_df = preprocessed_lactate_df[(preprocessed_lactate_df.relative_sample_date > 2*24) & (preprocessed_lactate_df.relative_sample_date < 3*72)]\n",
    "lactate_d_2_3_df = preprocessed_lactate_df[(preprocessed_lactate_df.relative_sample_date > 1*24) & (preprocessed_lactate_df.relative_sample_date < 3*72)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91bd4ac",
   "metadata": {},
   "source": [
    "## Lactate trajectories\n",
    "Group-based trajectory modeling (GBTM) analysis of lactate over time to evalutate the predictive potential of dynamic lactate trajectories for all-cause mortality in patients with ischemic stroke\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec2deca",
   "metadata": {},
   "source": [
    "## Group-based trajectory modeling (GBTM)\n",
    "We fit finite mixtures of quadratic lactate trajectories (time in hours from T0) to identify latent classes, then test whether class membership associates with 3-month mortality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f40a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for GBTM\n",
    "# Merge mortality outcome and restrict to a clinically meaningful window around T0\n",
    "timing_lower_bound = -12\n",
    "timing_upper_bound = 72\n",
    "\n",
    "analysis_window = preprocessed_lactate_df[(preprocessed_lactate_df['relative_sample_date'] > timing_lower_bound) &\n",
    "                                          (preprocessed_lactate_df['relative_sample_date'] < timing_upper_bound)].copy()\n",
    "\n",
    "# Ensure mortality outcome is available\n",
    "if '3M Death' not in analysis_window.columns:\n",
    "    analysis_window = analysis_window.merge(\n",
    "        outcome_df[['case_admission_id', '3M Death']],\n",
    "        on='case_admission_id',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "analysis_window['3M Death'] = pd.to_numeric(analysis_window['3M Death'], errors='coerce')\n",
    "print(f\"Patients with lactate in window: {analysis_window.case_admission_id.nunique()}\")\n",
    "print(f\"Patients with mortality label: {analysis_window.dropna(subset=['3M Death']).case_admission_id.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6448c0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit patient-level quadratic trajectories and mixture model to identify latent classes\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Toggle to use bayes_traj (Dirichlet process mixture) instead of sklearn GaussianMixture\n",
    "use_bayes_traj = False\n",
    "bayes_traj_k = 2\n",
    "bayes_traj_iters = 300\n",
    "\n",
    "# Set manual_k to an integer (e.g., 2, 3, 4, 5) to override automatic selection; keep None for auto\n",
    "manual_k = None\n",
    "\n",
    "# Force trajectories to be linear (no quadratic term) when True\n",
    "only_use_linear_trajectories = True\n",
    "\n",
    "# Derive per-patient quadratic coefficients (falls back to lower order if few points)\n",
    "def fit_quadratic(group: pd.DataFrame) -> pd.Series:\n",
    "    t = group['relative_sample_date'].values\n",
    "    y = group['value'].values\n",
    "    try:\n",
    "        if only_use_linear_trajectories:\n",
    "            if len(t) >= 2:\n",
    "                coef = np.polyfit(t, y, 1)\n",
    "                coef = np.array([0.0, coef[0], coef[1]])\n",
    "            else:\n",
    "                coef = np.array([0.0, 0.0, np.mean(y)])\n",
    "        else:\n",
    "            if len(t) >= 3:\n",
    "                coef = np.polyfit(t, y, 2)\n",
    "            elif len(t) == 2:\n",
    "                coef = np.polyfit(t, y, 1)\n",
    "                coef = np.array([0.0, coef[0], coef[1]])\n",
    "            else:\n",
    "                coef = np.array([0.0, 0.0, np.mean(y)])\n",
    "    except Exception:\n",
    "        coef = np.array([0.0, 0.0, np.mean(y)])\n",
    "    return pd.Series({\n",
    "        'beta2': coef[0],\n",
    "        'beta1': coef[1],\n",
    "        'beta0': coef[2],\n",
    "        'n_obs': len(t),\n",
    "        't_span': t.max() - t.min() if len(t) > 1 else 0.0\n",
    "    })\n",
    "\n",
    "traj_features = analysis_window.groupby('case_admission_id').apply(fit_quadratic).reset_index()\n",
    "feature_cols = ['beta1', 'beta0'] if only_use_linear_trajectories else ['beta2', 'beta1', 'beta0']\n",
    "\n",
    "# Winsorize coefficients to limit extreme outliers that can create single-point classes\n",
    "q_low = traj_features[feature_cols].quantile(0.01)\n",
    "q_high = traj_features[feature_cols].quantile(0.99)\n",
    "X = traj_features[feature_cols].clip(lower=q_low, upper=q_high, axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "if use_bayes_traj:\n",
    "    try:\n",
    "        from bayes_traj.mult_dp_regression import MultDPRegression\n",
    "        from bayes_traj import generate_prior\n",
    "        from bayes_traj.fit_stats import compute_waic2\n",
    "    except ImportError as e:\n",
    "        raise ImportError(\"bayes_traj not installed; run `pip install bayes-traj` in the project venv.\") from e\n",
    "\n",
    "    # Build design matrix for bayes_traj (intercept, time, optional time^2)\n",
    "    design_df = analysis_window[['case_admission_id', 'relative_sample_date', 'value']].dropna().copy()\n",
    "    design_df = design_df.rename(columns={'value': 'lactate_value'})\n",
    "    design_df['intercept'] = 1.0\n",
    "    design_df['time'] = design_df['relative_sample_date']\n",
    "    if not only_use_linear_trajectories:\n",
    "        design_df['time_sq'] = design_df['relative_sample_date'] ** 2\n",
    "    pred_cols = ['intercept', 'time']\n",
    "    if not only_use_linear_trajectories:\n",
    "        pred_cols.append('time_sq')\n",
    "    target_col = 'lactate_value'\n",
    "\n",
    "    # Data-driven priors for bayes_traj (falls back to OLS-based prior if helper not available)\n",
    "    prior_info = {\n",
    "        'w_mu0': {target_col: {p: 0.0 for p in pred_cols}},\n",
    "        'w_var0': {target_col: {p: 1.0 for p in pred_cols}},\n",
    "        'lambda_a0': {target_col: 1.0},\n",
    "        'lambda_b0': {target_col: 1.0},\n",
    "    }\n",
    "    num_trajs = np.array([max(1, bayes_traj_k - 1), bayes_traj_k + 1])\n",
    "    try:\n",
    "        prior_info = generate_prior.prior_info_from_df_gaussian(design_df, target_col, pred_cols, num_trajs, prior_info)\n",
    "    except AttributeError:\n",
    "        import statsmodels.api as sm\n",
    "        res_tmp = sm.OLS(design_df[target_col], design_df[pred_cols], missing='drop').fit()\n",
    "        fudge = 0.002\n",
    "        vars_est = fudge * design_df.shape[0] * res_tmp.HC0_se.values ** 2\n",
    "        for (i, p) in enumerate(pred_cols):\n",
    "            prior_info['w_mu0'][target_col][p] = res_tmp.params.values[i]\n",
    "            prior_info['w_var0'][target_col][p] = vars_est[i]\n",
    "        prec_mean = 1.0 / max(np.var(res_tmp.resid.values), 1e-8)\n",
    "        prec_var = (prec_mean * 0.5) ** 2\n",
    "        prior_info['lambda_b0'][target_col] = prec_mean / prec_var\n",
    "        prior_info['lambda_a0'][target_col] = prec_mean ** 2 / prec_var\n",
    "\n",
    "    # If prior_info generation failed or missed keys, fall back to simple defaults\n",
    "    if prior_info is None:\n",
    "        prior_info = {\n",
    "            'w_mu0': {target_col: {p: 0.0 for p in pred_cols}},\n",
    "            'w_var0': {target_col: {p: 1.0 for p in pred_cols}},\n",
    "            'lambda_a0': {target_col: 1.0},\n",
    "            'lambda_b0': {target_col: 1.0},\n",
    "        }\n",
    "    else:\n",
    "        for p in pred_cols:\n",
    "            prior_info.setdefault('w_mu0', {}).setdefault(target_col, {}).setdefault(p, 0.0)\n",
    "            prior_info.setdefault('w_var0', {}).setdefault(target_col, {}).setdefault(p, 1.0)\n",
    "        prior_info.setdefault('lambda_a0', {}).setdefault(target_col, 1.0)\n",
    "        prior_info.setdefault('lambda_b0', {}).setdefault(target_col, 1.0)\n",
    "\n",
    "    alpha = bayes_traj_k / np.log10(max(design_df['case_admission_id'].nunique(), 2))\n",
    "\n",
    "    w_mu0 = np.array([prior_info['w_mu0'][target_col][p] for p in pred_cols]).reshape(len(pred_cols), 1)\n",
    "    w_var0 = np.array([prior_info['w_var0'][target_col][p] for p in pred_cols]).reshape(len(pred_cols), 1)\n",
    "    lambda_a0 = np.array([prior_info['lambda_a0'][target_col]])\n",
    "    lambda_b0 = np.array([prior_info['lambda_b0'][target_col]])\n",
    "\n",
    "    mm = MultDPRegression(w_mu0, w_var0, lambda_a0, lambda_b0, 0.25, alpha, K=bayes_traj_k, prob_thresh=0.001)\n",
    "    mm.fit(target_names=[target_col], predictor_names=pred_cols, df=design_df,\n",
    "           groupby='case_admission_id', iters=bayes_traj_iters, verbose=False)\n",
    "\n",
    "    r_cols = [f\"traj_{i}\" for i in range(bayes_traj_k)]\n",
    "    r_df = pd.DataFrame(mm.R_, columns=r_cols)\n",
    "    r_df['case_admission_id'] = design_df['case_admission_id'].values\n",
    "    patient_probs = r_df.groupby('case_admission_id')[r_cols].mean()\n",
    "    patient_probs['traj_class'] = patient_probs[r_cols].idxmax(axis=1).str.replace('traj_', '', regex=False).astype(int) + 1\n",
    "    patient_probs['traj_class_prob'] = patient_probs[r_cols].max(axis=1)\n",
    "\n",
    "    min_frac = patient_probs['traj_class'].value_counts().min() / patient_probs.shape[0]\n",
    "    entropy = 1 + (patient_probs[r_cols].values * np.log(patient_probs[r_cols].values + 1e-12)).sum() / (patient_probs.shape[0] * np.log(bayes_traj_k))\n",
    "    waic2 = compute_waic2(mm)\n",
    "    n_obs = design_df.shape[0]\n",
    "    n_params = bayes_traj_k * len(pred_cols) + bayes_traj_k  # coefficients + variance terms\n",
    "    bic = np.nan\n",
    "    try:\n",
    "        log_like_attr = next((attr for attr in ['log_like_', 'log_like', 'loglik_', 'loglik', 'log_likelihood_', 'log_likelihood'] if hasattr(mm, attr)), None)\n",
    "        if log_like_attr is not None:\n",
    "            log_like_vals = np.atleast_1d(getattr(mm, log_like_attr))\n",
    "            log_like = float(np.ravel(log_like_vals)[-1])\n",
    "            bic = -2.0 * log_like + n_params * np.log(max(n_obs, 1))\n",
    "    except Exception:\n",
    "        bic = np.nan\n",
    "    # If bayes_traj does not expose log-likelihood, approximate BIC from WAIC2 (-2 * elpd) plus penalty\n",
    "    if np.isnan(bic):\n",
    "        bic = waic2 + n_params * np.log(max(n_obs, 1))\n",
    "\n",
    "    results_df = pd.DataFrame([{\n",
    "        'k': bayes_traj_k,\n",
    "        'bic': bic,\n",
    "        'waic2': waic2,\n",
    "        'entropy': entropy,\n",
    "        'min_frac': min_frac\n",
    "    }])\n",
    "\n",
    "    traj_features = traj_features.merge(patient_probs.reset_index()[['case_admission_id', 'traj_class', 'traj_class_prob']],\n",
    "                                        on='case_admission_id', how='left')\n",
    "    best_k = bayes_traj_k\n",
    "\n",
    "    print('bayes_traj fit completed (Dirichlet process mixture).')\n",
    "    print(results_df)\n",
    "    print(traj_features['traj_class'].value_counts().sort_index())\n",
    "else:\n",
    "    results = []\n",
    "    models = {}\n",
    "    for k in range(2, 6):\n",
    "        gm = GaussianMixture(n_components=k, covariance_type='full', random_state=0, n_init=10, reg_covar=1e-4)\n",
    "        gm.fit(X_scaled)\n",
    "        proba = gm.predict_proba(X_scaled)\n",
    "        pred = proba.argmax(axis=1)\n",
    "        n = len(pred)\n",
    "        min_frac = np.bincount(pred, minlength=k).min() / n\n",
    "        entropy = 1 + (proba * np.log(proba + 1e-12)).sum() / (n * np.log(k))\n",
    "        bic = gm.bic(X_scaled)\n",
    "        results.append({\n",
    "            'k': k,\n",
    "            'bic': bic,\n",
    "            'entropy': entropy,\n",
    "            'min_frac': min_frac\n",
    "        })\n",
    "        models[k] = gm\n",
    "\n",
    "    results_df = pd.DataFrame(results).sort_values('bic')\n",
    "    candidates = results_df[(results_df['entropy'] > 0.7) & (results_df['min_frac'] >= 0.05)].sort_values('bic')\n",
    "\n",
    "    if manual_k is not None:\n",
    "        if manual_k not in models:\n",
    "            raise ValueError(f\"manual_k={manual_k} not in fitted range 2-5\")\n",
    "        best_row = results_df[results_df['k'] == manual_k].iloc[0]\n",
    "        print(f'Manual override to k={manual_k}. Constraints not enforced for selection; metrics for chosen k shown below.')\n",
    "    elif not candidates.empty:\n",
    "        best_row = candidates.iloc[0]\n",
    "        print('Selected by constraints (entropy>0.7 & min_frac>=0.05) and lowest BIC among them.')\n",
    "    else:\n",
    "        best_row = results_df.iloc[0]\n",
    "        print('No model met both entropy > 0.7 and min group size >= 5%. Falling back to overall lowest BIC.')\n",
    "\n",
    "    best_k = int(best_row['k'])\n",
    "    best_model = models[best_k]\n",
    "    proba = best_model.predict_proba(X_scaled)\n",
    "    traj_features['traj_class'] = proba.argmax(axis=1) + 1  # 1-based class labels\n",
    "    traj_features['traj_class_prob'] = proba.max(axis=1)\n",
    "\n",
    "    print('Model selection table (sorted by BIC):')\n",
    "    print(results_df)\n",
    "    print(f\"Selected {best_k} classes (entropy>{best_row['entropy']:.3f}, min_frac>{best_row['min_frac']:.3f}, bic={best_row['bic']:.1f}).\")\n",
    "    print(traj_features['traj_class'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9cdc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize observed and class-average trajectories\n",
    "analysis_window = analysis_window.drop(columns=[c for c in analysis_window.columns if c.startswith('traj_class')], errors='ignore')\n",
    "analysis_window = analysis_window.merge(traj_features[['case_admission_id', 'traj_class']],\n",
    "                                        on='case_admission_id', how='left')\n",
    "\n",
    "time_grid = np.linspace(-12, 72, 60)\n",
    "coef_cols = ['beta2', 'beta1', 'beta0']\n",
    "class_curves = []\n",
    "for c in sorted(traj_features.traj_class.unique()):\n",
    "    coefs = traj_features[traj_features.traj_class == c][coef_cols].mean()\n",
    "    y_hat = coefs['beta2'] * time_grid ** 2 + coefs['beta1'] * time_grid + coefs['beta0']\n",
    "    class_curves.append(pd.DataFrame({\n",
    "        'relative_sample_date': time_grid,\n",
    "        'lactate_pred': y_hat,\n",
    "        'traj_class': c\n",
    "    }))\n",
    "\n",
    "plot_df = pd.concat(class_curves, ignore_index=True)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "# sns.lineplot(data=analysis_window, x='relative_sample_date', y='value', hue='traj_class',\n",
    "#              palette='tab10', estimator='median', errorbar=('ci', 95), alpha=0.3)\n",
    "\n",
    "sns.scatterplot(data=analysis_window, x='relative_sample_date', y='value', hue='traj_class',\n",
    "             palette='tab10', alpha=0.1)\n",
    "sns.lineplot(data=plot_df, x='relative_sample_date', y='lactate_pred', hue='traj_class',\n",
    "             palette='tab10', linewidth=3, legend=False)\n",
    "plt.axvline(0, color='k', linestyle='--', linewidth=1)\n",
    "plt.xlabel('Hours from T0')\n",
    "plt.ylabel('Lactate (mmol/L)')\n",
    "plt.title('Lactate trajectories by latent class')\n",
    "plt.xlim(-12, 72)\n",
    "plt.ylim(0,10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a53cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Association between trajectory class and 3-month mortality\n",
    "import statsmodels.api as sm\n",
    "\n",
    "mortality_df = traj_features.merge(outcome_df[['case_admission_id', '3M Death']], on='case_admission_id', how='left')\n",
    "mortality_df['3M Death'] = pd.to_numeric(mortality_df['3M Death'], errors='coerce')\n",
    "mortality_df = mortality_df.dropna(subset=['3M Death']).copy()\n",
    "mortality_df['3M Death'] = mortality_df['3M Death'].astype(float)\n",
    "mortality_df = mortality_df[mortality_df['3M Death'].isin([0.0, 1.0])]\n",
    "\n",
    "# Class-level mortality rates\n",
    "class_mortality = mortality_df.groupby('traj_class')['3M Death'].agg(['count', 'mean']).rename(columns={'mean': 'mortality_rate'})\n",
    "print(class_mortality)\n",
    "\n",
    "# Logistic regression with class dummies (reference = class 1)\n",
    "mortality_df = pd.get_dummies(mortality_df, columns=['traj_class'], drop_first=True, dtype=float)\n",
    "X_cols = [c for c in mortality_df.columns if c.startswith('traj_class_')]\n",
    "X = sm.add_constant(mortality_df[X_cols].astype(float))\n",
    "logit_model = sm.Logit(mortality_df['3M Death'], X).fit(disp=False)\n",
    "print(logit_model.summary())\n",
    "\n",
    "or_vals = np.exp(logit_model.params)\n",
    "ci = np.exp(logit_model.conf_int())\n",
    "pvals = logit_model.pvalues\n",
    "or_table = pd.DataFrame({'OR': or_vals, 'CI_lower': ci[0], 'CI_upper': ci[1], 'p_value': pvals})\n",
    "print('\\nOdds ratios (trajectory classes vs class 1 reference):')\n",
    "print(or_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f852d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Association between trajectory class and 3-month mRS\n",
    "mrs_df = traj_features.merge(outcome_df[['case_admission_id', '3M mRS']], on='case_admission_id', how='left')\n",
    "mrs_df['3M mRS'] = pd.to_numeric(mrs_df['3M mRS'], errors='coerce')\n",
    "mrs_df = mrs_df.dropna(subset=['3M mRS']).copy()\n",
    "mrs_df['traj_class'] = mrs_df['traj_class'].astype(int)\n",
    "\n",
    "# Class-level distribution of mRS scores\n",
    "mrs_counts = mrs_df.groupby('traj_class')['3M mRS'].value_counts().unstack(fill_value=0)\n",
    "mrs_summary = mrs_df.groupby('traj_class')['3M mRS'].agg(['count', 'median', 'mean'])\n",
    "print('mRS counts by trajectory class (rows=class, columns=mRS score):')\n",
    "print(mrs_counts)\n",
    "print('\\nClass-level mRS summary:')\n",
    "print(mrs_summary)\n",
    "\n",
    "# Ordinal logistic regression (proportional odds) with class 1 as reference\n",
    "exog = pd.get_dummies(mrs_df['traj_class'], prefix='traj_class', drop_first=True)\n",
    "ord_model = OrderedModel(mrs_df['3M mRS'], exog, distr='logit')\n",
    "ord_res = ord_model.fit(method='bfgs', disp=False)\n",
    "print(ord_res.summary())\n",
    "\n",
    "# Extract odds ratios for trajectory classes (thresholds omitted)\n",
    "coef_idx = [c for c in ord_res.params.index if c.startswith('traj_class_')]\n",
    "or_vals = np.exp(ord_res.params[coef_idx])\n",
    "ci = np.exp(ord_res.conf_int().loc[coef_idx])\n",
    "or_table = pd.DataFrame({'OR': or_vals, 'CI_lower': ci[0], 'CI_upper': ci[1]})\n",
    "print('\\nOdds ratios (trajectory classes vs class 1 reference):')\n",
    "print(or_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939623c5",
   "metadata": {},
   "source": [
    "## Model selection note\n",
    "- Lower (more negative) BIC is better.\n",
    "- Constrained candidates (entropy > 0.7, min group size ≥ 5%) currently: k=2 (BIC≈-12016) and k=3 (BIC≈-14121). The 3-class model has the lower BIC, so it is selected.\n",
    "- Models with k=4 or 5 have lower BIC but fail the 5% minimum group size criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1481f7",
   "metadata": {},
   "source": [
    "## Methods summary (stepwise)\n",
    "1. Cohort assembly: Linked EDS labs to registry via `case_admission_id`; excluded non-ischemic, non-acute, under 18, intra-hospital strokes, and refusals. Added T0 (stroke or arrival time).\n",
    "2. Lactate preprocessing: Loaded all lab files, harmonized labels/units, removed implausible/non-numeric values, restricted to lactate. Computed relative sample time (hours from T0) and limited analysis window to -12 to +72 hours.\n",
    "3. Outcome derivation: From registry, derived 3-month mortality (`3M Death`), setting hospital deaths to mRS=6 and binarizing death indicators.\n",
    "4. Feature construction: For each admission, fit patient-level lactate trajectories (quadratic if ≥3 points; linear if 2; mean if 1) to obtain coefficients `beta2`, `beta1`, `beta0`; winsorized coefficients at 1st/99th percentiles and standardized them.\n",
    "5. Mixture modeling (GBTM proxy): Default uses Gaussian mixtures (k=2..5) on standardized coefficients with constraint filter (entropy>0.7, min class size≥5%), lowest-BIC candidate selected unless overridden by `manual_k`; optional `use_bayes_traj=True` fits a Dirichlet-process regression mixture (via `bayes_traj`) on raw trajectories with data-driven priors and reports WAIC2/entropy/min_frac.\n",
    "6. Class assignment: Assigned each admission to the class with highest posterior probability (`traj_class`) and stored maximum posterior as `traj_class_prob` (classification certainty).\n",
    "7. Visualization: Plotted observed lactate by time (median with CI) and class-mean quadratic curves over -12 to +72h.\n",
    "8. Mortality association: Merged class labels with outcomes; summarized class-specific mortality; ran logistic regression (reference = class 1) with class dummies to estimate odds ratios and 95% CIs.\n",
    "9. Reporting: Printed the model selection table (BIC, entropy, min_frac) and class counts; odds-ratio table for mortality associations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ada035",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collaterals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
